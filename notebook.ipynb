{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69b1a395",
   "metadata": {},
   "source": [
    "# Entraînement d'un modèle multilingue de classification de texte (IMDb + Allociné)\n",
    "\n",
    "Ce notebook implémente un pipeline complet de classification binaire de sentiments à partir de textes en anglais (IMDb) et en français (Allociné). Il inclut :\n",
    "- Le nettoyage des données textuelles,\n",
    "- La fusion et la préparation des jeux de données,\n",
    "- L'utilisation d'un tokenizer multilingue (`distilbert-base-multilingual-cased`),\n",
    "- L'entraînement avec `Trainer` de HuggingFace,\n",
    "- L'évaluation de la performance du modèle,\n",
    "- Une démonstration de prédiction.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d524c1d",
   "metadata": {},
   "source": [
    "## Importation des bibliothèques nécessaires\n",
    "\n",
    "On commence par importer les bibliothèques utiles pour le traitement des données, le modèle pré-entraîné et l'entraînement :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4def721f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, concatenate_datasets\n",
    "from transformers import AutoModelForSequenceClassification, Trainer, TrainingArguments, AutoTokenizer\n",
    "import numpy as np\n",
    "import re\n",
    "from evaluate import load\n",
    "import torch\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1592b1f5",
   "metadata": {},
   "source": [
    "## Nettoyage du texte et prétraitement\n",
    "\n",
    "Avant d'entraîner un modèle de classification, il est important de nettoyer les textes pour enlever les balises HTML, les caractères spéciaux et les espaces inutiles. On définit ci-dessous une fonction `clean_text` utilisée dans deux fonctions de prétraitement : une pour les textes en anglais (IMDb) et une autre pour le français (Allociné).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59223d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = re.sub(r'<br\\s*/?>', ' ', text)\n",
    "    text = re.sub(r'[^a-zA-ZÀ-ÿ0-9,.!?\\'\\\" ]+', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    return text.lower().strip()\n",
    "\n",
    "def preprocess_function_en(examples):\n",
    "    examples[\"text\"] = [clean_text(t) for t in examples[\"text\"]]\n",
    "    return examples\n",
    "\n",
    "def preprocess_function_fr(examples):\n",
    "    examples[\"text\"] = [clean_text(t) for t in examples[\"review\"]]\n",
    "    return examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85dc61b3",
   "metadata": {},
   "source": [
    "## Chargement et prétraitement des jeux de données\n",
    "\n",
    "Nous utilisons deux jeux de données pour l'entraînement du modèle :\n",
    "\n",
    "- **IMDb** : pour les critiques en anglais\n",
    "- **Allociné** : pour les critiques en français\n",
    "\n",
    "Chaque dataset est nettoyé avec la fonction `clean_text` définie précédemment. Le jeu de données Allociné ne contient pas de séparation explicite entre entraînement et test. Nous réalisons donc une séparation manuelle à l'aide de `train_test_split`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a65de40",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_en = load_dataset(\"imdb\")\n",
    "dataset_fr = load_dataset(\"allocine\")\n",
    "\n",
    "dataset_en = dataset_en.map(preprocess_function_en, batched=True)\n",
    "dataset_fr = dataset_fr.map(preprocess_function_fr, batched=True)\n",
    "\n",
    "dataset_fr = dataset_fr[\"train\"].train_test_split(test_size=0.2, seed=42)\n",
    "dataset_fr = {\n",
    "    \"train\": dataset_fr[\"train\"],\n",
    "    \"test\": dataset_fr[\"test\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc27e600",
   "metadata": {},
   "source": [
    "## Fusion des jeux de données multilingues\n",
    "\n",
    "Nous fusionnons les jeux de données anglais (IMDb) et français (Allociné) pour créer un ensemble multilingue. L’objectif est d’entraîner un modèle capable de gérer les deux langues simultanément.\n",
    "\n",
    "- Les jeux d'entraînement sont concaténés et mélangés.\n",
    "- Une partie des données d'entraînement est utilisée comme jeu de validation (20%).\n",
    "- Les jeux de test sont également concaténés pour évaluer les performances globales.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20785f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_datasets(ds1, ds2):\n",
    "    train = concatenate_datasets([ds1[\"train\"], ds2[\"train\"]]).shuffle(seed=42)\n",
    "    test = concatenate_datasets([ds1[\"test\"], ds2[\"test\"]]).shuffle(seed=42)\n",
    "    train_valid_split = train.train_test_split(test_size=0.2, seed=42)\n",
    "    return train_valid_split[\"train\"], train_valid_split[\"test\"], test\n",
    "\n",
    "train_dataset, valid_dataset, test_dataset = merge_datasets(dataset_en, dataset_fr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dce279e",
   "metadata": {},
   "source": [
    "## Tokenisation des textes\n",
    "\n",
    "Nous utilisons un **tokenizer multilingue** (`distilbert-base-multilingual-cased`) pour convertir les textes en vecteurs numériques utilisables par le modèle.\n",
    "\n",
    "- Le texte est tronqué et remplit jusqu'à une longueur maximale de 256 tokens.\n",
    "- La tokenisation est appliquée par lot (`batched=True`) pour plus d'efficacité.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c519e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-multilingual-cased\")\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, max_length=256)\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "valid_dataset = valid_dataset.map(tokenize_function, batched=True)\n",
    "test_dataset = test_dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e95a413",
   "metadata": {},
   "source": [
    "## Préparation des datasets pour PyTorch\n",
    "\n",
    "Pour faciliter l’entraînement avec `transformers` et PyTorch, nous :\n",
    "\n",
    "- Supprimons la colonne `text` qui n’est plus nécessaire après tokenisation.\n",
    "- Renommons la colonne `label` en `labels` pour correspondre à l’API du modèle.\n",
    "- Convertissons les datasets au format PyTorch (`set_format(\"torch\")`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf8e5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(ds):\n",
    "    if \"text\" in ds.column_names:\n",
    "        ds = ds.remove_columns([\"text\"])\n",
    "    ds = ds.rename_column(\"label\", \"labels\")\n",
    "    ds.set_format(\"torch\")\n",
    "    return ds\n",
    "\n",
    "train_dataset = prepare_dataset(train_dataset)\n",
    "valid_dataset = prepare_dataset(valid_dataset)\n",
    "test_dataset = prepare_dataset(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702ba610",
   "metadata": {},
   "source": [
    "## Chargement du modèle et configuration de l'entraînement\n",
    "\n",
    "- Chargement du modèle **DistilBERT multilingue** pré-entraîné, adapté pour une classification binaire (`num_labels=2`).\n",
    "- Configuration des paramètres d’entraînement via `TrainingArguments` :\n",
    "  - Dossier de sortie `./results`\n",
    "  - Taux d’apprentissage de `2e-5`\n",
    "  - Batch size de 16 pour entraînement et évaluation\n",
    "  - Entraînement sur 3 epochs\n",
    "  - Décroissance du poids (weight decay) pour régularisation\n",
    "  - Logs sauvegardés dans `./logs`\n",
    "  - Pas de rapport externe (`report_to=[]`)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636e57d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-multilingual-cased\", num_labels=2)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=500,\n",
    "    report_to=[],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46bd5c5",
   "metadata": {},
   "source": [
    "## Définition de la métrique d’évaluation\n",
    "\n",
    "Nous utilisons la métrique d’**accuracy** pour évaluer les performances du modèle.  \n",
    "La fonction `compute_metrics` prend en entrée les logits du modèle et les labels réels,  \n",
    "puis calcule la précision des prédictions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ec6c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b08de9",
   "metadata": {},
   "source": [
    "## Entraînement et évaluation du modèle\n",
    "\n",
    "- Création d’un objet `Trainer` avec le modèle, les arguments d’entraînement, les datasets d'entraînement et de validation, et la fonction d’évaluation.\n",
    "- Lancement de l’entraînement avec `trainer.train()`.\n",
    "- Évaluation sur le dataset de validation.\n",
    "- Affichage de la précision (accuracy) obtenue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81910ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=valid_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "eval_result = trainer.evaluate()\n",
    "print(f\"Accuracy sur validation: {eval_result['eval_accuracy']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b973b353",
   "metadata": {},
   "source": [
    "## Sauvegarde du modèle et du tokenizer\n",
    "\n",
    "Après l’entraînement, on sauvegarde le modèle et le tokenizer  \n",
    "dans un dossier local pour une utilisation future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04499fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"./my_model\")\n",
    "tokenizer.save_pretrained(\"./my_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760e8696",
   "metadata": {},
   "source": [
    "## Test de prédiction sur un exemple\n",
    "\n",
    "On passe le modèle en mode évaluation,  \n",
    "on prépare un texte d’exemple,  \n",
    "on le nettoie, on le tokenize,  \n",
    "puis on obtient la prédiction avec confiance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5ed71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "review_text = \"Le film était incroyable et très émouvant.\"\n",
    "cleaned_text = clean_text(review_text)\n",
    "inputs = tokenizer(cleaned_text, return_tensors=\"pt\", truncation=True, padding=True, max_length=256)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "    logits = outputs.logits\n",
    "    probs = F.softmax(logits, dim=-1)\n",
    "    predicted_class = torch.argmax(probs, dim=-1).item()\n",
    "\n",
    "labels_map = {0: \"négatif\", 1: \"positif\"}\n",
    "print(f\"Texte : {review_text}\")\n",
    "print(f\"Prédiction : {labels_map[predicted_class]} (confiance : {probs[0][predicted_class]:.2f})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
