
# PrÃ©diction de Sentiments Multilingue (FR/EN)

Cette application web permet Ã  un utilisateur de saisir un texte libre et dâ€™obtenir en temps rÃ©el la **prÃ©diction du sentiment (positif ou nÃ©gatif)** associÃ© Ã  ce texte. Elle repose sur un modÃ¨le de classification fine-tunÃ© sur des donnÃ©es multilingues (`IMDb` en anglais et `AllocinÃ©` en franÃ§ais).

## ğŸ¥ PrÃ©sentation vidÃ©o

Vous pouvez regarder une dÃ©monstration de ce projet en vidÃ©o ici :

ğŸ‘‰ [Voir la vidÃ©o de prÃ©sentation](Video/Explication.mp4)

## ğŸŒ DÃ©mo en ligne

Vous pouvez tester l'application ici :

ğŸ‘‰ [Tester l'application en ligne](https://sentiments-classification-project.streamlit.app/)


## FonctionnalitÃ©s

-  **Nettoyage du texte** : suppression des balises HTML, des caractÃ¨res spÃ©ciaux et des espaces superflus.
-  **Chargement optimisÃ© du modÃ¨le** : utilisation de `@st.cache_resource` pour accÃ©lÃ©rer les appels du modÃ¨le.
-  **ModÃ¨le multilingue** : basÃ© sur `distilbert-base-multilingual-cased` fine-tunÃ© sur des avis en franÃ§ais et en anglais.
-  **Interface intuitive** : conÃ§ue avec `Streamlit` pour une expÃ©rience utilisateur simple et agrÃ©able.
-  **Affichage dynamique** :
  - Sentiment **positif** â†’ boÃ®te verte avec une icÃ´ne souriante ğŸ˜„
  - Sentiment **nÃ©gatif** â†’ boÃ®te rouge avec une icÃ´ne triste ğŸ˜
- **Score de confiance** affichÃ© avec chaque prÃ©diction.

##  DonnÃ©es utilisÃ©es

- **IMDb** : avis de films en anglais
- **AllocinÃ©** : critiques de films en franÃ§ais

Les deux jeux de donnÃ©es ont Ã©tÃ© nettoyÃ©s, fusionnÃ©s et rÃ©Ã©chantillonnÃ©s pour Ã©quilibrer l'entraÃ®nement et la validation.

##  EntraÃ®nement

- Tokenizer : `distilbert-base-multilingual-cased`
- EntraÃ®nement avec `Trainer` de Transformers
- Accuracy Ã©valuÃ©e via la mÃ©trique `accuracy`
- EntraÃ®nement sur 3 epochs avec `AdamW` et `weight decay`

## ModÃ¨le prÃ©-entraÃ®nÃ© disponible

Le modÃ¨le fine-tunÃ© est Ã©galement **disponible sur Hugging Face Hub** et peut Ãªtre chargÃ© directement depuis ce dÃ©pÃ´t, ce qui permet dâ€™Ã©viter de relancer lâ€™entraÃ®nement localement.

Pour lâ€™utiliser, il suffit de charger le modÃ¨le avec :  
```python
from transformers import AutoModelForSequenceClassification, AutoTokenizer

model_name = "FATIMA-ZAHRA-Z/my_model"
model = AutoModelForSequenceClassification.from_pretrained(model_name)
tokenizer = AutoTokenizer.from_pretrained(model_name)

```
## DÃ©pendances
 ### Pour l'entraÃ®nement du modÃ¨le
- transformers : pour le modÃ¨le BERT multilingue et le tokenizer
  
- datasets : pour le chargement et la gestion des jeux de donnÃ©es
  
- evaluate : pour le calcul des mÃ©triques dâ€™Ã©valuation
- torch : pour l'entraÃ®nement avec PyTorch
  
- numpy : pour les opÃ©rations numÃ©riques (comme lâ€™argmax sur les prÃ©dictions).
  
- re : pour le nettoyage des textes (suppression de balises HTML, ponctuation, etc.).

### Pour lâ€™application Streamlit
- streamlit : pour crÃ©er lâ€™interface web

- transformers : pour charger le modÃ¨le fine-tunÃ©

- torch : pour faire les prÃ©dictions
  
- re : pour le nettoyage des textes (suppression de balises HTML, ponctuation, etc.).
  
##  Lancement

### EntraÃ®nement du modÃ¨le
```bash
python train_model.py
```
###  Installation des dÃ©pendances
```bash
pip install -r requirements.txt
```
### Lancer l'application
```bash
streamlit run app.py
```


  
  ## Exemples de prÃ©diction

- Texte : *"Le film Ã©tait incroyable et trÃ¨s Ã©mouvant."* â†’ **Positif ğŸ˜„** 
- Texte : *"Je me suis ennuyÃ© pendant toute la rÃ©union."* â†’ **NÃ©gatif ğŸ˜**





