
# Pr√©diction de Sentiments Multilingue (FR/EN)

Cette application web permet √† un utilisateur de saisir un texte libre et d‚Äôobtenir en temps r√©el la **pr√©diction du sentiment (positif ou n√©gatif)** associ√© √† ce texte. Elle repose sur un mod√®le de classification fine-tun√© sur des donn√©es multilingues (`IMDb` en anglais et `Allocin√©` en fran√ßais).

## üåê D√©mo en ligne

L‚Äôapplication est accessible ici üëâ [Tester l'application en ligne](https://sentiments-classification-project.streamlit.app/)


## Fonctionnalit√©s

-  **Nettoyage du texte** : suppression des balises HTML, des caract√®res sp√©ciaux et des espaces superflus.
-  **Chargement optimis√© du mod√®le** : utilisation de `@st.cache_resource` pour acc√©l√©rer les appels du mod√®le.
-  **Mod√®le multilingue** : bas√© sur `distilbert-base-multilingual-cased` fine-tun√© sur des avis en fran√ßais et en anglais.
-  **Interface intuitive** : con√ßue avec `Streamlit` pour une exp√©rience utilisateur simple et agr√©able.
-  **Affichage dynamique** :
  - Sentiment **positif** ‚Üí bo√Æte verte avec une ic√¥ne souriante üòÑ
  - Sentiment **n√©gatif** ‚Üí bo√Æte rouge avec une ic√¥ne triste üòû
- **Score de confiance** affich√© avec chaque pr√©diction.

##  Donn√©es utilis√©es

- **IMDb** : avis de films en anglais
- **Allocin√©** : critiques de films en fran√ßais

Les deux jeux de donn√©es ont √©t√© nettoy√©s, fusionn√©s et r√©√©chantillonn√©s pour √©quilibrer l'entra√Ænement et la validation.

##  Entra√Ænement

- Tokenizer : `distilbert-base-multilingual-cased`
- Entra√Ænement avec `Trainer` de Transformers
- Accuracy √©valu√©e via la m√©trique `accuracy`
- Entra√Ænement sur 3 epochs avec `AdamW` et `weight decay`

## Mod√®le pr√©-entra√Æn√© disponible

Le mod√®le fine-tun√© est √©galement **disponible sur Hugging Face Hub** et peut √™tre charg√© directement depuis ce d√©p√¥t, ce qui permet d‚Äô√©viter de relancer l‚Äôentra√Ænement localement.

Pour l‚Äôutiliser, il suffit de charger le mod√®le avec :  
```python
from transformers import AutoModelForSequenceClassification, AutoTokenizer

model_name = "FATIMA-ZAHRA-Z/my_model"
model = AutoModelForSequenceClassification.from_pretrained(model_name)
tokenizer = AutoTokenizer.from_pretrained(model_name)

```
## D√©pendances
 ### Pour l'entra√Ænement du mod√®le
- transformers : pour le mod√®le BERT multilingue et le tokenizer
  
- datasets : pour le chargement et la gestion des jeux de donn√©es
  
- evaluate : pour le calcul des m√©triques d‚Äô√©valuation
- torch : pour l'entra√Ænement avec PyTorch
  
- numpy : pour les op√©rations num√©riques (comme l‚Äôargmax sur les pr√©dictions).
  
- re : pour le nettoyage des textes (suppression de balises HTML, ponctuation, etc.).

### Pour l‚Äôapplication Streamlit
- streamlit : pour cr√©er l‚Äôinterface web

- transformers : pour charger le mod√®le fine-tun√©

- torch : pour faire les pr√©dictions
  
- re : pour le nettoyage des textes (suppression de balises HTML, ponctuation, etc.).
  
##  Lancement

### Entra√Ænement du mod√®le
```bash
python train_model.py
```
###  Installation des d√©pendances
```bash
pip install -r requirements.txt
```
### Lancer l'application
```bash
streamlit run app.py
```


  
  ## Exemples de pr√©diction

- Texte : *"Le film √©tait incroyable et tr√®s √©mouvant."* ‚Üí **Positif üòÑ** 
- Texte : *"Je me suis ennuy√© pendant toute la r√©union."* ‚Üí **N√©gatif üòû**





